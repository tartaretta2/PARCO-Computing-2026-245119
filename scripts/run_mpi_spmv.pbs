#!/bin/bash
#PBS -N SpMV_Dual
#PBS -o ../results/SpMV_Dual.out
#PBS -e ../results/SpMV_Dual.err
#PBS -q short_cpuQ
#PBS -l walltime=06:00:00
#PBS -l select=4:ncpus=16:mpiprocs=16:mem=16gb

module load gcc91
module load openmpi-3.0.0--gcc-9.1.0

# Suppress MPI warnings
export OMPI_MCA_oob=^ud
export OMPI_MCA_btl_openib_warn_default_gid_prefix=0
export OMPI_MCA_mpi_cuda_support=0
export OMPI_MCA_btl=^openib

cd $PBS_O_WORKDIR || exit 1

# NODE INFORMATION (one file per node)
NP=$(wc -l < "$PBS_NODEFILE")

echo "=========================================="
echo "Collecting node information via MPI"
echo "Total MPI ranks: $NP"
echo "=========================================="

mpirun -np "$NP" bash -c '
if [[ "$OMPI_COMM_WORLD_LOCAL_RANK" == "0" ]]; then
    host=$(hostname)
    outfile="nodeinfo_${host}.txt"

    echo "Hostname: $host"        >  "$outfile"
    echo "---- lscpu ----"        >> "$outfile"
    lscpu                      >> "$outfile"
    echo "---- memory ----"       >> "$outfile"
    free -h                    >> "$outfile"
fi
'


BASE_DIR=".."
MATRIX_DIR="${BASE_DIR}/data_matrices"
RESULTS_DIR="${BASE_DIR}/results"
BIN_DIR="${RESULTS_DIR}/bin"


echo "=========================================="
echo "SpMV Dual Evaluation: MPI vs MPI+OpenMP"
echo "=========================================="
echo "Date: $(date)"
echo ""

mkdir -p "${RESULTS_DIR}/mpi_logs"
mkdir -p "${RESULTS_DIR}/mpix_logs"

# SETUP CSV FILES

# MPI-only CSVs
if [[ ! -f "${RESULTS_DIR}/mpi_times.csv" ]]; then
    echo "matrix,num_procs,num_threads,M,N,nnz,comm_time,comp_time,total_time" > "${RESULTS_DIR}/mpi_times.csv"
fi

if [[ ! -f "${RESULTS_DIR}/mpi_load_balance.csv" ]]; then
    echo "matrix,num_procs,num_threads,min_nnz,avg_nnz,max_nnz,imbalance_pct" > "${RESULTS_DIR}/mpi_load_balance.csv"
fi

# MPI+OpenMP CSVs
if [[ ! -f "${RESULTS_DIR}/mpix_times.csv" ]]; then
    echo "matrix,num_procs,num_threads,M,N,nnz,comm_time,comp_time,total_time" > "${RESULTS_DIR}/mpix_times.csv"
fi

if [[ ! -f "${RESULTS_DIR}/mpix_load_balance.csv" ]]; then
    echo "matrix,num_procs,num_threads,min_nnz,avg_nnz,max_nnz,imbalance_pct" > "${RESULTS_DIR}/mpix_load_balance.csv"
fi

REPEATS=10
REAL_MATRICES=($(find "$MATRIX_DIR" -maxdepth 1 -name "*.mtx" -type f))

if [[ ${#REAL_MATRICES[@]} -eq 0 ]]; then
    echo "[ERROR] No matrices found in $MATRIX_DIR"
    exit 1
fi

echo "Found ${#REAL_MATRICES[@]} matrices:"
for mat in "${REAL_MATRICES[@]}"; do
    echo "  - $(basename $mat)"
done
echo ""

# PART 1: MPI-ONLY (Pure MPI)
echo "=========================================="
echo "PART 1: MPI-Only Strong Scaling"
echo "=========================================="

cd $BASE_DIR || exit 1
make clean
make  # Compile without OpenMP

if [[ $? -ne 0 ]]; then
    echo "[ERROR] MPI-only compilation failed!"
    exit 1
fi

echo "✓ MPI-only binary compiled"
echo ""

cd $PBS_O_WORKDIR || exit 1

STRONG_PROCS=(1 2 4 8 16 32 64)

for MATRIX_PATH in "${REAL_MATRICES[@]}"; do
    MATRIX_NAME=$(basename "$MATRIX_PATH" .mtx)
    
    echo "=== Matrix: ${MATRIX_NAME} (MPI-only) ==="
    LOG_FILE="${RESULTS_DIR}/mpi_logs/${MATRIX_NAME}_strong.log"
    
    echo "Strong Scaling - Pure MPI - Matrix: ${MATRIX_NAME}" > "$LOG_FILE"
    echo "Date: $(date)" >> "$LOG_FILE"
    echo "" >> "$LOG_FILE"
    
    for P in "${STRONG_PROCS[@]}"; do
        echo "  [MPI-only] P=$P..."
        echo "--- P=$P ---" >> "$LOG_FILE"
        mpirun -np $P "${BIN_DIR}/spmv_mpi" "$MATRIX_PATH" "$REPEATS" 1 >> "$LOG_FILE" 2>&1
        
        if [[ $? -ne 0 ]]; then
            echo "  [ERROR] Failed with P=$P"
        else
            echo "  ✓ Completed"
        fi
        
        echo "" >> "$LOG_FILE"
    done
    
    echo ""
done

# PART 2: MPI+OpenMP (Hybrid)
echo "=========================================="
echo "PART 2: MPI+OpenMP Hybrid Strong Scaling"
echo "=========================================="

cd $BASE_DIR || exit 1
make clean
make USE_OPENMP=1  # Compile with OpenMP

if [[ $? -ne 0 ]]; then
    echo "[ERROR] MPI+OpenMP compilation failed!"
    exit 1
fi

echo "✓ MPI+OpenMP binary compiled"
echo ""

cd $PBS_O_WORKDIR || exit 1

HYBRID_CONFIGS=(
    "16:1"
    "8:2"
    "4:4"
    "2:8"
    "1:16"
)

for MATRIX_PATH in "${REAL_MATRICES[@]}"; do
    MATRIX_NAME=$(basename "$MATRIX_PATH" .mtx)
    
    echo "=== Matrix: ${MATRIX_NAME} (MPI+OpenMP) ==="
    LOG_FILE="${RESULTS_DIR}/mpix_logs/${MATRIX_NAME}_hybrid.log"
    
    echo "Hybrid MPI+OpenMP - Matrix: ${MATRIX_NAME}" > "$LOG_FILE"
    echo "Date: $(date)" >> "$LOG_FILE"
    echo "" >> "$LOG_FILE"
    
    for CONFIG in "${HYBRID_CONFIGS[@]}"; do
        P=$(echo $CONFIG | cut -d: -f1)
        T=$(echo $CONFIG | cut -d: -f2)
        
        export OMP_NUM_THREADS=$T
        export OMP_PROC_BIND=close
        export OMP_PLACES=cores
        
        echo "  [Hybrid] P=${P} × T=${T}..."
        echo "--- P=${P} × T=${T} ---" >> "$LOG_FILE"
        mpirun -np $P "${BIN_DIR}/spmv_mpi" "$MATRIX_PATH" "$REPEATS" $T >> "$LOG_FILE" 2>&1
        
        if [[ $? -ne 0 ]]; then
            echo "  [ERROR] Failed with P=${P} × T=${T}"
        else
            echo "  ✓ Completed"
        fi
        
        echo "" >> "$LOG_FILE"
    done
    
    echo ""
done

# PART 3: WEAK SCALING (MPI-only)
echo "=========================================="
echo "PART 3: Weak Scaling (MPI-only)"
echo "=========================================="

cd $BASE_DIR || exit 1
make clean
make  # Ricompile without OpenMP for weak scaling

cd $PBS_O_WORKDIR || exit 1

WEAK_PROCS=(1 2 4 8 16 32 64)
BASE_SIZE=1000
AVG_NNZ_PER_ROW=10

SYNTHETIC_DIR="${MATRIX_DIR}/synthetic"
mkdir -p "$SYNTHETIC_DIR"

WEAK_LOG="${RESULTS_DIR}/mpi_logs/weak_scaling.log"
echo "Weak Scaling - Synthetic Matrices" > "$WEAK_LOG"
echo "Date: $(date)" >> "$WEAK_LOG"
echo "" >> "$WEAK_LOG"

for P in "${WEAK_PROCS[@]}"; do
    N=$((BASE_SIZE * P))
    MATRIX_FILE="${SYNTHETIC_DIR}/random_${N}x${N}.mtx"
    
    if [[ ! -f "$MATRIX_FILE" ]]; then
        echo "  Generating ${N}x${N} matrix..."
        "${BIN_DIR}/generate_matrix" "$MATRIX_FILE" "$N" "$AVG_NNZ_PER_ROW"
    fi
    
    echo "  [Weak] P=$P, Size=${N}x${N}..."
    echo "--- P=$P, Size=${N}x${N} ---" >> "$WEAK_LOG"
    mpirun -np $P "${BIN_DIR}/spmv_mpi" "$MATRIX_FILE" "$REPEATS" 1 >> "$WEAK_LOG" 2>&1
    
    if [[ $? -ne 0 ]]; then
        echo "  [ERROR] Failed with P=$P"
    else
        echo "  ✓ Completed"
    fi
    
    echo "" >> "$WEAK_LOG"
done

echo ""

# PYTHON ANALYSIS
echo "=========================================="
echo "Python Analysis"
echo "=========================================="

module load python-3.10.14_gcc91

VENV_DIR="${BASE_DIR}/.venv"
if [[ ! -d "$VENV_DIR" ]]; then
    echo "Creating virtual environment..."
    python3 -m venv "$VENV_DIR"
fi

source "$VENV_DIR/bin/activate"

pip install --quiet --upgrade pip
pip install --quiet pandas matplotlib numpy

ANALYSIS_SCRIPT="mpi_analysis.py"

if [[ -f "$ANALYSIS_SCRIPT" ]]; then
    echo "Running Python analysis..."
    python3 "$ANALYSIS_SCRIPT"
    
    if [[ $? -eq 0 ]]; then
        echo "✓ Analysis completed"
    else
        echo "[ERROR] Analysis script failed"
    fi
else
    echo "[WARNING] Analysis script not found: $ANALYSIS_SCRIPT"
fi

deactivate

# SUMMARY
echo ""
echo "=========================================="
echo "Job Completed Successfully!"
echo "=========================================="
echo ""
echo "Experiments completed:"
echo "  1. ✓ MPI-only strong scaling (1-64 procs)"
echo "  2. ✓ MPI+OpenMP hybrid (P×T configs)"
echo "  3. ✓ Weak scaling (MPI-only)"
echo ""
echo "Results:"
echo "  MPI-only:"
echo "    - ${RESULTS_DIR}/mpi_times.csv"
echo "    - ${RESULTS_DIR}/mpi_load_balance.csv"
echo "    - ${RESULTS_DIR}/mpi_logs/"
echo ""
echo "  MPI+OpenMP:"
echo "    - ${RESULTS_DIR}/mpix_times.csv"
echo "    - ${RESULTS_DIR}/mpix_load_balance.csv"
echo "    - ${RESULTS_DIR}/mpix_logs/"
echo ""
echo "  Plots:"
echo "    - ${RESULTS_DIR}/plots/"
echo ""
echo "Date: $(date)"
echo "=========================================="